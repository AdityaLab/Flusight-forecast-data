{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f59c215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LosAlamos_NAU-CModel_Flu', 'SigSci-TSENS', 'Flusight-baseline', 'LUcompUncertLab-VAR2K_plusCOVID', 'CU-ensemble', 'JHUAPL-Gecko', 'SGroup-RandomForest', 'VTSanghani-ExogModel', 'SigSci-CREG', 'UMass-trends_ensemble', 'CMU-TimeSeries', 'SGroup-SIkJalpha', 'CEID-Walk', 'LUcompUncertLab-humanjudgment', 'Flusight-ensemble', 'PSI-DICE', 'IEM_Health-FluProject', 'UT_FluCast-Voltaire', 'LUcompUncertLab-VAR2_plusCOVID', 'UVAFluX-Ensemble', 'LUcompUncertLab-VAR2K', 'LUcompUncertLab-TEVA', 'GH-Flusight', 'MOBS-GLEAM_FLUH', 'LUcompUncertLab-VAR2', 'GT-FluFNP-raw', 'GT-FluFNP']\n",
      "9\n",
      "LosAlamos_NAU-CModel_Flu\n",
      "9\n",
      "SigSci-TSENS\n",
      "9\n",
      "Flusight-baseline\n",
      "9\n",
      "LUcompUncertLab-VAR2K_plusCOVID\n",
      "9\n",
      "CU-ensemble\n",
      "6\n",
      "JHUAPL-Gecko\n",
      "5\n",
      "SGroup-RandomForest\n",
      "8\n",
      "VTSanghani-ExogModel\n",
      "9\n",
      "SigSci-CREG\n",
      "7\n",
      "UMass-trends_ensemble\n",
      "9\n",
      "CMU-TimeSeries\n",
      "9\n",
      "SGroup-SIkJalpha\n",
      "7\n",
      "CEID-Walk\n",
      "6\n",
      "LUcompUncertLab-humanjudgment\n",
      "9\n",
      "Flusight-ensemble\n",
      "9\n",
      "PSI-DICE\n",
      "9\n",
      "IEM_Health-FluProject\n",
      "9\n",
      "UT_FluCast-Voltaire\n",
      "9\n",
      "LUcompUncertLab-VAR2_plusCOVID\n",
      "9\n",
      "UVAFluX-Ensemble\n",
      "9\n",
      "LUcompUncertLab-VAR2K\n",
      "9\n",
      "LUcompUncertLab-TEVA\n",
      "6\n",
      "GH-Flusight\n",
      "6\n",
      "MOBS-GLEAM_FLUH\n",
      "8\n",
      "LUcompUncertLab-VAR2\n",
      "9\n",
      "GT-FluFNP-raw\n",
      "9\n",
      "GT-FluFNP\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is for parsing from CDC's github repo\n",
    "    Output: score card containing all models\n",
    "    i.e., \n",
    "    model, forecast_week, ahead, location (as region abbreviation), type, quantile, value\n",
    "    e.g.\n",
    "    GT-FluFNP, 202205, 1, CA, point, NaN, 843\n",
    "    GT-FluFNP, 202205, 1, CA, quantile, 0.01, 338\n",
    "        ....\n",
    "        GT-FluFNP, 202205, 2, CA, point, NaN, 900\n",
    "        GT-FluFNP, 202205, 2, CA, quantile, 0.01, 438\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from epiweeks import Week\n",
    "import pdb\n",
    "\n",
    "# death_target = ['1 wk ahead inc death' , '2 wk ahead inc death' , '3 wk ahead inc death' , '4 wk ahead inc death']\n",
    "\n",
    "data_ew = Week.thisweek(system=\"CDC\") - 1  # -1 because we have data for the previous (ending) week\n",
    "DIR =  './data-forecasts/'\n",
    "models = [file.split(DIR)[1] for file in glob.glob(DIR + '/*') if \".md\" not in file]\n",
    "location_df = pd.read_csv('data-locations/locations.csv')\n",
    "location_dict = {location_df['location'][i]:location_df['abbreviation'][i] for i in range(len(location_df))}\n",
    "# for each model, get all submissions\n",
    "df_list = []\n",
    "print(models)\n",
    "for model in models:\n",
    "    model_dir = DIR + '/' + model + '/' \n",
    "\n",
    "    all_items_path = np.array(glob.glob(model_dir + '*.csv'))  # list all csv files' paths\n",
    "    all_items = [path.replace(model_dir, '') for path in all_items_path]  #list of all csv files' names\n",
    "\n",
    "    \"\"\"\n",
    "    remove forecasts that were duplicated in a given week (if any)\n",
    "    forecasts file should be unique for each epiweek\n",
    "    \"\"\"\n",
    "    subm_dict = {}\n",
    "    for i, item in enumerate(all_items):\n",
    "        date = datetime.strptime(item[:10], '%Y-%m-%d')\n",
    "        epiweek  = date.isocalendar()[1]\n",
    "        if epiweek in subm_dict.keys():\n",
    "            if subm_dict[epiweek][0] <= date:\n",
    "                subm_dict[epiweek] = (date, i)\n",
    "        else:\n",
    "            subm_dict[epiweek] = (date, i)\n",
    "\n",
    "    select = [ value[1] for key, value in subm_dict.items()]\n",
    "    select_paths = all_items_path[select]\n",
    "\n",
    "\n",
    "    data_model = []\n",
    "    for path in select_paths:\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        \"\"\"\n",
    "            create epiweek column\n",
    "        \"\"\"\n",
    "        date = path.split('/')[-1][:10]\n",
    "        # epiweek ends on Saturday, but submission is until Monday. \n",
    "        # we can subtract 2 days, thus, submission on Monday will be considered in the prev week  \n",
    "        # this also aligns submission week and data\n",
    "        date = datetime.strptime(date, '%Y-%m-%d') - timedelta(days=2)\n",
    "        forecast_week = Week.fromdate(date)\n",
    "        df['forecast_week'] = forecast_week\n",
    "        #pdb.set_trace()\n",
    "        data_model.append(df)\n",
    "\n",
    "\n",
    "    # join all dataframes saved in data_model\n",
    "\n",
    "    \"\"\"\n",
    "        select, rename and sort columns\n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "        convert location to region abbreviation\n",
    "    \"\"\"\n",
    "    print(len(data_model))\n",
    "    print(model)\n",
    "    df = pd.concat(data_model, ignore_index=True, sort=False)\n",
    "    df = df.rename(columns={'target': 'ahead'})\n",
    "    model_list = []\n",
    "    df['location']= df['location'].astype(str)\n",
    "    for i in range(len(df)):  \n",
    "        key = df['location'][i]\n",
    "        if len(key) == 1: \n",
    "            key = '0' + key\n",
    "        df.at[i, 'location'] = location_dict[key]\n",
    "        df.at[i, 'ahead'] = df['ahead'][i][0]\n",
    "        model_list.append(model)\n",
    "    df['model'] = model\n",
    "    df = df[['model', 'forecast_week', 'ahead', 'location', 'type', 'quantile', 'value']]\n",
    "    final_row = {'model': [], 'forecast_week': [], 'ahead':[], 'location':[],'type':[],'quantile':[],\n",
    "             'value':[]}\n",
    "    for index, row in df.iterrows():\n",
    "        if row['quantile'] == 0.5 and model == 'Flusight-ensemble': \n",
    "            final_row['model'].append(row['model'])\n",
    "            final_row['forecast_week'].append(row['forecast_week'])\n",
    "            final_row['ahead'].append(row['ahead'])\n",
    "            final_row['location'].append(row['location'])\n",
    "            final_row['type'].append('point')\n",
    "            final_row['quantile'].append(np.nan)\n",
    "            final_row['value'].append(row['value'])\n",
    "    df2 = pd.DataFrame(final_row)\n",
    "    df3 = pd.concat([df,df2], ignore_index = False)\n",
    "    df3 = df3.sort_values(by=['forecast_week', 'location', 'ahead', 'type'], ascending=[True, True,True,True])\n",
    "    df_list.append(df3)  \n",
    "df = pd.concat(df_list, ignore_index=True, sort=False)\n",
    "df = df.sort_values(by=['model','forecast_week', 'location', 'ahead', 'type'], ascending=[True,True, True,True,True])\n",
    "df.to_csv('./predictions.csv',index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "156fd538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LosAlamos_NAU-CModel_Flu\n",
      "SigSci-TSENS\n",
      "Flusight-baseline\n",
      "LUcompUncertLab-VAR2K_plusCOVID\n",
      "CU-ensemble\n",
      "JHUAPL-Gecko\n",
      "SGroup-RandomForest\n",
      "VTSanghani-ExogModel\n",
      "SigSci-CREG\n",
      "UMass-trends_ensemble\n",
      "CMU-TimeSeries\n",
      "SGroup-SIkJalpha\n",
      "CEID-Walk\n",
      "LUcompUncertLab-humanjudgment\n",
      "Flusight-ensemble\n",
      "PSI-DICE\n",
      "IEM_Health-FluProject\n",
      "README.md\n",
      "UT_FluCast-Voltaire\n",
      "METADATA.md\n",
      "LUcompUncertLab-VAR2_plusCOVID\n",
      "UVAFluX-Ensemble\n",
      "LUcompUncertLab-VAR2K\n",
      "LUcompUncertLab-TEVA\n",
      "GH-Flusight\n",
      "MOBS-GLEAM_FLUH\n",
      "LUcompUncertLab-VAR2\n",
      "GT-FluFNP-raw\n",
      "GT-FluFNP\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(DIR + '/*'):\n",
    "    print(file.split(DIR)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b294502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2e3fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-f156e1a7fcb1>:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  z = np.arange(3, dtype=np.int)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b6246df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.957617998123169\n",
      "0.0\n",
      "0.6375894010066986\n",
      "1.620467758178711\n",
      "2.1095148801803587\n",
      "2.1444329738616945\n",
      "2.2644848823547363\n",
      "2.5354020595550537\n",
      "2.63372004032135\n",
      "2.664825999736786\n",
      "2.721835231781006\n",
      "2.81559591293335\n",
      "2.957617998123169\n",
      "3.072873091697693\n",
      "3.1612223625183105\n",
      "3.2074337005615234\n",
      "3.251999616622925\n",
      "3.4100457429885864\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.5151335477828964\n",
      "4.289033865928646\n",
      "5.381228952407841\n",
      "3.48996901512146\n",
      "1.3488049411773682\n",
      "1.582910993695259\n",
      "2.2530653715133666\n",
      "3.4424407482147217\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "5.213014078140256\n",
      "6.184170722961428\n",
      "6.893884968757629\n",
      "7.709536004066457\n",
      "8.690273122787483\n",
      "2.734231948852539\n",
      "0.0\n",
      "0.0\n",
      "0.0457495808601379\n",
      "0.4021731853485108\n",
      "1.0403863072395323\n",
      "1.3810546398162842\n",
      "1.4895933866500854\n",
      "1.989180445671081\n",
      "2.1520814895629883\n",
      "2.3926609039306643\n",
      "2.488811874389649\n",
      "2.7342320680618286\n",
      "3.045658588409424\n",
      "3.1166412830352783\n",
      "3.2971587896347048\n",
      "3.3751745223999023\n",
      "3.48996901512146\n",
      "3.521234750747681\n",
      "3.856310224533079\n",
      "4.442107295989991\n",
      "5.411520957946777\n",
      "6.150433230400084\n",
      "6.503322830200211\n",
      "2.9992308616638184\n",
      "0.0\n",
      "0.0\n",
      "0.4583379149436951\n",
      "1.2761991977691651\n",
      "2.104336261749268\n",
      "2.223128080368042\n",
      "2.56334125995636\n",
      "2.707416534423828\n",
      "2.8622382044792176\n",
      "2.93899917602539\n",
      "2.977769136428833\n",
      "2.999230742454529\n",
      "3.146391451358795\n",
      "3.1841869354248047\n",
      "3.19152204990387\n",
      "3.377515053749084\n",
      "3.484082221984864\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.48996901512146\n",
      "3.705875015258788\n",
      "4.130477261543274\n",
      "4.299456701278695\n",
      "24.984920501708984\n",
      "8.745167369842529\n",
      "9.682554125785828\n",
      "12.322540760040283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>forecast_week</th>\n",
       "      <th>ahead</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>quantile</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1067154</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.957618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067155</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067156</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.637589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067157</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1.620468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067158</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.109515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067249</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>4</td>\n",
       "      <td>AK</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4.299457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067250</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.984921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067251</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8.745167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067252</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.025</td>\n",
       "      <td>9.682554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067253</th>\n",
       "      <td>VTSanghani-ExogModel</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.050</td>\n",
       "      <td>12.322541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  forecast_week  ahead location      type  \\\n",
       "1067154  VTSanghani-ExogModel         202201      1       AK     point   \n",
       "1067155  VTSanghani-ExogModel         202201      1       AK  quantile   \n",
       "1067156  VTSanghani-ExogModel         202201      1       AK  quantile   \n",
       "1067157  VTSanghani-ExogModel         202201      1       AK  quantile   \n",
       "1067158  VTSanghani-ExogModel         202201      1       AK  quantile   \n",
       "...                       ...            ...    ...      ...       ...   \n",
       "1067249  VTSanghani-ExogModel         202201      4       AK  quantile   \n",
       "1067250  VTSanghani-ExogModel         202201      1       AL     point   \n",
       "1067251  VTSanghani-ExogModel         202201      1       AL  quantile   \n",
       "1067252  VTSanghani-ExogModel         202201      1       AL  quantile   \n",
       "1067253  VTSanghani-ExogModel         202201      1       AL  quantile   \n",
       "\n",
       "         quantile      value  \n",
       "1067154       NaN   2.957618  \n",
       "1067155     0.010   0.000000  \n",
       "1067156     0.025   0.637589  \n",
       "1067157     0.050   1.620468  \n",
       "1067158     0.100   2.109515  \n",
       "...           ...        ...  \n",
       "1067249     0.990   4.299457  \n",
       "1067250       NaN  24.984921  \n",
       "1067251     0.010   8.745167  \n",
       "1067252     0.025   9.682554  \n",
       "1067253     0.050  12.322541  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"predictions.csv\")\n",
    "df = df.query('model == \"VTSanghani-ExogModel\"')\n",
    "for i in df.head(100)['value']: \n",
    "    print(i)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2189fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
