{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf0e26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from epiweeks import Week\n",
    "from metrics import *\n",
    "EPS = 1e-6\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78744bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "df_ground_truth = pd.read_csv('ground_truth.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb072fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth.head()\n",
    "df_grnd = df_ground_truth[['epiweek', 'region', 'cdc_flu_hosp']]\n",
    "df_grnd = df_grnd[df_grnd['epiweek']>=202201]\n",
    "df_grnd = df_grnd.rename(\n",
    "    columns = {'epiweek':\"predicted_week\", \"cdc_flu_hosp\":\"value\", \"region\":\"location\"}\n",
    ")\n",
    "df_grnd['location'] = df_grnd['location'].str.replace('X', 'US')\n",
    "df_grnd['location'] = df_grnd['location'].str.replace('TUS', 'TX')\n",
    "df_grnd = df_grnd.sort_values('location', kind = 'mergesort')\n",
    "# df_grnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6356e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './predictions.csv' \n",
    "df_total = pd.read_csv(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191cc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['model'].nunique()\n",
    "df_final = df_total.copy()\n",
    "all_model_names = np.array(df_final['model'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e27f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_names = np.array(df_final['model'].drop_duplicates())\n",
    "df_gt = df_final[df_final['model']=='GT-FluFNP']\n",
    "\n",
    "# GT-FluFNP model hasn't predicted for some locations \n",
    "all_regions = np.array(df_gt['location'].drop_duplicates())\n",
    "regions_ground_truth = np.array(df_grnd['location'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f471fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point = df_final[df_final['type']=='point']\n",
    "df_quant = df_final[df_final['type']=='quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb33a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = np.array(df_point['forecast_week'].drop_duplicates())\n",
    "max_week = df_grnd['predicted_week'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ffc1614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/80/kmkjmw951tz6y67zc2c8fyd00000gn/T/ipykernel_34785/2765094017.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_point['predicted_week'] = df_point['forecast_week']+df_point['ahead']\n"
     ]
    }
   ],
   "source": [
    "df_point['predicted_week'] = df_point['forecast_week']+df_point['ahead']\n",
    "\n",
    "# Have ground truth only till week 10  \n",
    "\n",
    "df_point = df_point[df_point['predicted_week']<=max_week] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d79f04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging the two datasets on predicted week\n",
    "df_newpoint = pd.merge(df_point, df_grnd, on = \"predicted_week\")\n",
    "# Removing all unnecessary merges\n",
    "df_newpoint = df_newpoint[df_newpoint['location_x'] == df_newpoint['location_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b3f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_all = []\n",
    "nrmse_all = []\n",
    "model_all= []\n",
    "mape_all = []\n",
    "week_ahead = []\n",
    "regions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f0dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gauthamgururajan/Desktop/GT/Flusight/Flusight-forecast-data/metrics.py:19: RuntimeWarning: Mean of empty slice.\n",
      "  return np.sqrt(((predictions - targets) ** 2).mean())\n",
      "/Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "for model in all_model_names:\n",
    "    for i in range(1, 5):\n",
    "        for region in all_regions:\n",
    "            sample = df_newpoint[ \n",
    "                                (df_newpoint['model']==model)  \n",
    "                                 & (df_newpoint['ahead']==i)  \n",
    "                                 & (df_newpoint['location_x']==region)\n",
    "                                ]['value_x'].values\n",
    "            target = df_newpoint[ \n",
    "                                (df_newpoint['model']==model)  \n",
    "                                & (df_newpoint['ahead']==i)  \n",
    "                                & (df_newpoint['location_x']==region) \n",
    "                                ]['value_y'].values\n",
    "            rmse_all.append(rmse(sample, target))\n",
    "\n",
    "#             Deal with inf values\n",
    "            target = np.array([EPS if x ==0 else x for x in target]).reshape(\n",
    "                (len(target), 1)\n",
    "            )\n",
    "            mape_all.append(mape(sample, target))\n",
    "            model_all.append(model)\n",
    "            week_ahead.append(i)\n",
    "            regions.append(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f84fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_scores = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'Model':model_all,\n",
    "        'RMSE':rmse_all,\n",
    "        'MAPE':mape_all,\n",
    "        'Weeks ahead':week_ahead,\n",
    "        'Location':regions\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe8d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_scores.to_csv('point_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "850e255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is ground truth\n",
    "df_quant = df_final[df_final['type']=='quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29cf6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_val = (df_quant['value']-df_quant['value'].min())/(df_quant['value'].max()-df_quant['value'].min())\n",
    "\n",
    "norm_df_quant = df_quant.copy()\n",
    "norm_df_quant['predicted_week'] = (\n",
    "    norm_df_quant['forecast_week']+norm_df_quant['ahead']\n",
    ")\n",
    "norm_df_quant = norm_df_quant[norm_df_quant['predicted_week']<=max_week] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e985f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_ahead = []\n",
    "regions = []\n",
    "crps_all = []\n",
    "ls_all = []\n",
    "model_all = []\n",
    "cs_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aace1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime warning - invalid value occurs during multiply -- ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39447b8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling scores of model  CEID-Walk\n",
      "Model 0/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  CMU-TimeSeries\n",
      "Model 1/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  CU-ensemble\n",
      "Model 2/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  Flusight-baseline\n",
      "Model 3/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  Flusight-ensemble\n",
      "Model 4/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  GH-Flusight\n",
      "Model 5/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  GT-FluFNP\n",
      "Model 6/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  GT-FluFNP-raw\n",
      "Model 7/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  IEM_Health-FluProject\n",
      "Model 8/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  JHUAPL-Gecko\n",
      "Model 9/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LUcompUncertLab-TEVA\n",
      "Model 10/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LUcompUncertLab-VAR2\n",
      "Model 11/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LUcompUncertLab-VAR2K\n",
      "Model 12/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LUcompUncertLab-VAR2K_plusCOVID\n",
      "Model 13/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LUcompUncertLab-VAR2_plusCOVID\n",
      "Model 14/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LUcompUncertLab-humanjudgment\n",
      "Model 15/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  LosAlamos_NAU-CModel_Flu\n",
      "Model 16/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  MOBS-GLEAM_FLUH\n",
      "Model 17/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  PSI-DICE\n",
      "Model 18/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  SGroup-RandomForest\n",
      "Model 19/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  SGroup-SIkJalpha\n",
      "Model 20/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  SigSci-CREG\n",
      "Model 21/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  SigSci-TSENS\n",
      "Model 22/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  UMass-trends_ensemble\n",
      "Model 23/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  UT_FluCast-Voltaire\n",
      "Model 24/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  UVAFluX-Ensemble\n",
      "Model 25/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Compiling scores of model  VTSanghani-ExogModel\n",
      "Model 26/27\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n"
     ]
    }
   ],
   "source": [
    "# All models\n",
    "count = 0\n",
    "for model in all_model_names:\n",
    "    print('Compiling scores of model ', model)\n",
    "    print(f\"Model {count}/{len(all_model_names)}\")\n",
    "    count += 1\n",
    "    \n",
    "#     All Weeks ahead\n",
    "    for i in range(1, 5):\n",
    "        print('Week ahead ', i)\n",
    "        \n",
    "#         All regions\n",
    "        for region in all_regions:\n",
    "            \n",
    "#             Dataset with information about Ground truth ('value_y') and predictions ('value_x') \n",
    "            target = df_newpoint[ \n",
    "                                (df_newpoint['model']==model)\n",
    "                                & (df_newpoint['ahead']==i)\n",
    "                                & (df_newpoint['location_x']==region)\n",
    "            ]\n",
    "            \n",
    "            norm_model = norm_df_quant[ \n",
    "                                (norm_df_quant['model']==model)\n",
    "                                & (norm_df_quant['ahead']==i)  \n",
    "                                & (norm_df_quant['location']==region)\n",
    "            ]\n",
    "            \n",
    "            mean_ = []\n",
    "            std_ = []\n",
    "            var_ = []\n",
    "            tg_vals = []\n",
    "            pred_vals = []\n",
    "            \n",
    "            weeks = np.array(target['forecast_week'].drop_duplicates())\n",
    "            if(len(weeks)!=0):\n",
    "                for week in weeks:\n",
    "    #                 Append point predictions\n",
    "                    point_val = target[ (target['forecast_week']==week)][\n",
    "                        'value_x'\n",
    "                    ].values\n",
    "                    mean_.append(point_val)\n",
    "                    if(len(point_val)==0):\n",
    "                        print(i, week, region, model)\n",
    "\n",
    "    #                 Append point pred as predictions\n",
    "                    predval = target[ (target['forecast_week']==week)][\n",
    "                        'value_y'\n",
    "                    ].values \n",
    "                    pred_vals.append(predval)\n",
    "                \n",
    "    #                     Append ground truth as target\n",
    "                    tgval = target[ (target['forecast_week']==week)]['value_y'].values\n",
    "                    tg_vals.append(tgval)\n",
    "\n",
    "    #                 Find std from quantiles\n",
    "                    b = norm_model[  \n",
    "                                    (norm_model['forecast_week']==week) \n",
    "                                    & (norm_model['quantile']==0.75)\n",
    "                    ]['value'].values\n",
    "                    a = norm_model[  \n",
    "                                    (norm_model['forecast_week']==week)\n",
    "                                    & (norm_model['quantile']==0.25)\n",
    "                    ]['value'].values\n",
    "                    std = (b-a)/1.35\n",
    "                \n",
    "                    var = std**2\n",
    "                    std_.append(std)\n",
    "                    var_.append(var)\n",
    "\n",
    "                std_ = np.array(std_)\n",
    "                var_ = np.array(var_)\n",
    "                pred_vals = np.array(pred_vals)\n",
    "                mean_ = np.array(mean_)\n",
    "                tg_vals = np.array(tg_vals)\n",
    "\n",
    "                if(len(tg_vals)==0):\n",
    "                    print(\n",
    "                        \"No target found for week ahead \",\n",
    "                        i, \n",
    "                        \" region \",\n",
    "                        region,\n",
    "                        \"model \",\n",
    "                        model\n",
    "                    )\n",
    "\n",
    "#             Calculate ls and crps\n",
    "                if(0 in std_):\n",
    "                    cr_target = np.array([EPS if x ==0 else x for x in tg_vals], dtype=object).reshape(\n",
    "                        (len(tg_vals), 1)\n",
    "                    )\n",
    "                    cr = float(mape(pred_vals, cr_target))\n",
    "                    ls = -10\n",
    "#                     print(cr, ls)\n",
    "                else:\n",
    "                    cr = crps(mean_, std_, tg_vals)\n",
    "                    ls = log_score(mean_, std_, tg_vals, window = 0.1)\n",
    "                    if(ls<-10):\n",
    "                        ls = -10\n",
    "#                     print(cr, ls, \"hi\")\n",
    "                auc, cs, _ = get_pr(mean_, std_**2, tg_vals)\n",
    "\n",
    "                \n",
    "#                 if(ls<-10 or math.isnan(ls)):\n",
    "#                     ls = -10\n",
    "#                 elif(ls>10):\n",
    "#                     ls = 10\n",
    "#                 if(math.isnan(cr)):\n",
    "#                     cr = 0\n",
    "                    \n",
    "                crps_all.append(cr)\n",
    "                ls_all.append(ls)\n",
    "#                 print(cs)\n",
    "                cs_all.append(cs)\n",
    "                \n",
    "            else:\n",
    "                crps_all.append(np.nan)\n",
    "                ls_all.append(np.nan)\n",
    "                cs_all.append(np.nan)\n",
    "            week_ahead.append(i)\n",
    "            regions.append(region)\n",
    "            model_all.append(model)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4399e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spread_scores = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'Model':model_all,\n",
    "        'Weeks ahead':week_ahead,\n",
    "        'Location':regions,\n",
    "        'LS':ls_all,\n",
    "        'CRPS':crps_all,\n",
    "        'CS':cs_all\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f41f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spread_scores.to_csv('spread_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
